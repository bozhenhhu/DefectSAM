{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segment_anything import SamPredictor, sam_model_registry\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import scipy.io as sio\n",
    "import os \n",
    "import random \n",
    "import json\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefectDataset(Dataset):\n",
    "    def __init__(self, data_root='defect/test_set.txt', label_dir='defect/data/labels_coco/labels',\n",
    "                 height=1024, width=1024, heating_num=50, batchsize=8, bbox_shift=10):\n",
    "        file = open(data_root, 'r')\n",
    "        self.data_path = [line.strip() for line in file]\n",
    "        file.close()\n",
    "\n",
    "        self.label_dir = label_dir\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "        self.heating_num = heating_num\n",
    "        self.batchsize = batchsize\n",
    "\n",
    "        self.bbox_shift = bbox_shift\n",
    "        print(f\"number of samples: {len(self.data_path)}\")\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_path)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # load npy image (1024, 1024, 3), [0,1]\n",
    "        file_path = self.data_path[index]\n",
    "        basename = file_path.split('/')[-1].split('.')[0]\n",
    "        label_path = os.path.join(self.label_dir,'{}_label.png'.format(basename))\n",
    "\n",
    "        label_img = cv2.imread(label_path, 0)\n",
    "        scale_x = self.width / label_img.shape[1]\n",
    "        scale_y = self.height / label_img.shape[0]\n",
    "        label_img = cv2.resize(label_img, (self.width, self.height))\n",
    "        label_img[label_img < 120] = 120\n",
    "        label_img[label_img != 120 ] = 0 #0,black,1 white\n",
    "        label_img[label_img != 0] = 255 #label convert\n",
    "        label_img = label_img / 255.\n",
    "\n",
    "        data_struct = sio.loadmat(file_path)\n",
    "        data = data_struct['data']\n",
    "        t_len = data.shape[2]\n",
    "        sub = data[:, :, -1]\n",
    "        data = data[:, :, self.heating_num:min(t_len, self.heating_num+160)]\n",
    "        data = data - np.tile(sub[:, :, np.newaxis], (1, 1, data.shape[2]))\n",
    "\n",
    "        random_indices = np.random.choice(data.shape[2], size=self.batchsize, replace=False)\n",
    "        data = data[:, :, random_indices]\n",
    "        data = cv2.resize(data, (self.width, self.height))\n",
    "        data = np.transpose(data, (2, 0, 1))\n",
    "        # data = data / 255.\n",
    "\n",
    "        labels = np.tile(label_img[np.newaxis, :, :], (data.shape[0], 1, 1))\n",
    "        data = np.tile(data[:, np.newaxis, :, :], (1, 3, 1, 1))\n",
    "\n",
    "        label_json = os.path.join(self.label_dir,'{}_label.json'.format(basename))\n",
    "        bboxes = []\n",
    "        with open(label_json, 'r') as fp:\n",
    "            label_coord = json.load(fp)\n",
    "            num_classes = len(label_coord['shapes'])\n",
    "            masked_image = np.zeros((labels.shape[0], num_classes, labels.shape[1], labels.shape[2]))\n",
    "            for i in range(num_classes):\n",
    "                shapes = label_coord['shapes'][i]\n",
    "                points = shapes['points']\n",
    "                x_min, y_min = points[0][0], points[0][1]\n",
    "                x_max, y_max = points[1][0], points[1][1]\n",
    "                x_min = int(x_min * scale_x)\n",
    "                x_max = int(x_max * scale_x)\n",
    "                y_min = int(y_min * scale_y)\n",
    "                y_max = int(y_max * scale_y)\n",
    "                x_min = max(0, x_min - random.randint(0, self.bbox_shift))\n",
    "                x_max = min(self.width, x_max + random.randint(0, self.bbox_shift))\n",
    "                y_min = max(0, y_min - random.randint(0, self.bbox_shift))\n",
    "                y_max = min(self.height, y_max + random.randint(0, self.bbox_shift))\n",
    "                bboxes.append([x_min, y_min, x_max, y_max])\n",
    "                masked_image[:, i, y_min:y_max, x_min:x_max] = labels[:, y_min:y_max, x_min:x_max]\n",
    "\n",
    "        bboxes = np.array(bboxes)\n",
    "        bboxes = np.tile(bboxes[np.newaxis, :, :], (data.shape[0], 1, 1))\n",
    "\n",
    "        return (\n",
    "            torch.tensor(masked_image).float(),\n",
    "            torch.tensor(data).float(),\n",
    "            torch.tensor(bboxes).float(),\n",
    "            basename,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 1024\n",
    "height = 1024\n",
    "heating_num=50\n",
    "sample_rate=4\n",
    "batchsize = 1\n",
    "device = \"cuda\"\n",
    "sam_checkpoint = \"weights/sam_vit_b_01ec64.pth\"\n",
    "model_type = \"vit_b\"\n",
    "sam = sam_model_registry[model_type](checkpoint=sam_checkpoint)\n",
    "sam.to(device=device)\n",
    "\n",
    "predictor = SamPredictor(sam)\n",
    "test_dataset = DefectDataset(data_root='defect/test_set.txt', height=height, width=width, \n",
    "                                 heating_num=heating_num, batchsize=sample_rate)\n",
    "test_dataloader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=batchsize,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "#     data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "#     labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "#     bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "#     print(data.shape, labels.shape, bboxes.shape)\n",
    "\n",
    "#     _, axs = plt.subplots(1, 2, figsize=(25, 25))\n",
    "#     idx = random.randint(0, 4)\n",
    "#     img = data[idx].cpu().permute(1, 2, 0).numpy()\n",
    "#     axs[0].imshow(img/255.)\n",
    "#     axs[0].axis(\"off\")\n",
    "#     boxes = bboxes[idx].cpu().numpy()\n",
    "#     for box in boxes:\n",
    "#         show_box(box, axs[0])\n",
    "#     # set title\n",
    "#     axs[0].set_title(names_temp[0])\n",
    "\n",
    "#     img = labels[idx].cpu().permute(1, 2, 0).numpy()\n",
    "#     axs[1].imshow(img[:, :, 0])\n",
    "#     for box in boxes:\n",
    "#         show_box(box, axs[1])\n",
    "#     axs[1].axis(\"off\")\n",
    "#     # set title\n",
    "#     axs[1].set_title(names_temp[0]+'label')\n",
    "   \n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "#     # plt.subplots_adjust(wspace=0.01, hspace=0)\n",
    "#     # plt.savefig(\"./defect/data_sanitycheck_0.png\", bbox_inches=\"tight\", dpi=300)\n",
    "#     # plt.close()\n",
    "#     # show the example\n",
    "#     print('ok')\n",
    "#     break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "#     data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "#     labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "#     bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "#     print(data.shape, labels.shape, bboxes.shape)\n",
    "#     # boxes_np = bboxes.detach().cpu().numpy()\n",
    "#     labels, data = labels.to(device), data.to(device)\n",
    "#     bboxes = bboxes.to(device)\n",
    "#     # data = data.permute(0, 2, 3, 1)\n",
    "#     print(data.shape)\n",
    "#     batched_output = []\n",
    "#     for i in range(data.shape[0]):\n",
    "#         print(data[i].shape)\n",
    "#         predictor.set_image(data[i])\n",
    "#         transformed_boxes = predictor.transform.apply_boxes_torch(bboxes[i], data[i].shape[:2])\n",
    "#         masks, _, _ = predictor.predict_torch(\n",
    "#             point_coords=None,\n",
    "#             point_labels=None,\n",
    "#             boxes=transformed_boxes,\n",
    "#             multimask_output=False,\n",
    "#         )\n",
    "#         batched_output.append(masks)\n",
    "\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization\n",
    "\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device.device)\n",
    "    print('before permute', image.shape)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "\n",
    "for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "    data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "    labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "    bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "    print(data.shape, labels.shape, bboxes.shape)\n",
    "    boxes_np = bboxes.detach().cpu().numpy()\n",
    "    # labels, data = labels.to(device), data.to(device)\n",
    "    bboxes = bboxes.to(device)\n",
    "    data_np = data.permute(0, 2, 3, 1)\n",
    "    data_np = data_np.cpu().numpy()\n",
    "    data_np = data_np.astype(np.uint8)\n",
    "    print(data.shape)\n",
    "    \n",
    "    batched_input = []\n",
    "    for i in range(data.shape[0]):\n",
    "        img_tmp = prepare_image(data_np[i], resize_transform, sam)\n",
    "        print(img_tmp.shape)\n",
    "        box_tmp = resize_transform.apply_boxes_torch(bboxes[i], data[i].shape[:2])\n",
    "        print(box_tmp.shape)\n",
    "        input = {'image': prepare_image(data_np[i], resize_transform, sam),\n",
    "         'boxes': resize_transform.apply_boxes_torch(bboxes[i], data_np[i].shape[:2]),\n",
    "         'original_size': data_np[i].shape[:2]}\n",
    "        batched_input.append(input)\n",
    "    batched_output = sam(batched_input, multimask_output=False)\n",
    "    print('mask shape:', batched_output[0]['masks'].shape)\n",
    "\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    ax = fig.add_subplot(111)\n",
    "    img = data[0].cpu().numpy()\n",
    "    img = img.transpose(1, 2, 0)\n",
    "    # img = data_np[0].astype(float)\n",
    "    ax.imshow(img/255.)\n",
    "\n",
    "    for mask in batched_output[0]['masks']:\n",
    "        show_mask(mask.cpu().numpy(), ax, random_color=False)\n",
    "    \n",
    "    for box in boxes_np[0]:\n",
    "        show_box(box, ax)\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    # plt.shxianow()\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate IOU\n",
    "\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device.device)\n",
    "    # print('before permute', image.shape)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "\n",
    "def calculate_iou(y_hat, y):\n",
    "    intersection = np.logical_and(y_hat, y)\n",
    "    union = np.logical_or(y_hat, y)\n",
    "    iou = np.sum(intersection) / np.sum(union)\n",
    "    return iou\n",
    "\n",
    "IOU_plane = []\n",
    "IOU_R = []\n",
    "R_type = ['036g', '029g', '035g', '012g']\n",
    "for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "    data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "    labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "    bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "    print(data.shape, labels.shape, bboxes.shape)\n",
    "    boxes_np = bboxes.detach().cpu().numpy()\n",
    "    # labels, data = labels.to(device), data.to(device)\n",
    "    bboxes = bboxes.to(device)\n",
    "    data_np = data.permute(0, 2, 3, 1)\n",
    "    data_np = data_np.cpu().numpy()\n",
    "    data_np = data_np.astype(np.uint8)\n",
    "    # print(data.shape)\n",
    "    \n",
    "    batched_input = []\n",
    "    for i in range(data.shape[0]):\n",
    "        img_tmp = prepare_image(data_np[i], resize_transform, sam)\n",
    "        print(img_tmp.shape)\n",
    "        box_tmp = resize_transform.apply_boxes_torch(bboxes[i], data[i].shape[:2])\n",
    "        print(box_tmp.shape)\n",
    "        input = {'image': prepare_image(data_np[i], resize_transform, sam),\n",
    "         'boxes': resize_transform.apply_boxes_torch(bboxes[i], data_np[i].shape[:2]),\n",
    "         'original_size': data_np[i].shape[:2]}\n",
    "        batched_input.append(input)\n",
    "    batched_output = sam(batched_input, multimask_output=False)\n",
    "    print('mask shape:', batched_output[0]['masks'].shape)\n",
    "\n",
    "\n",
    "    labels = labels.cpu().numpy()\n",
    "    for i in range(data.shape[0]):\n",
    "        # img = data[i].cpu().numpy()\n",
    "        # img = img.transpose(1, 2, 0)\n",
    "        label_img = labels[0]\n",
    "        label_img = label_img.astype(bool)\n",
    "        pre_img = batched_output[i]['masks']\n",
    "        pre_img = pre_img.squeeze(1)\n",
    "        pre_img = pre_img.cpu().numpy()\n",
    "        pre_img = pre_img.astype(bool)\n",
    "        y = label_img[0]\n",
    "        y_hat = pre_img[0]\n",
    "        for j in range(label_img.shape[0]):\n",
    "            y = np.logical_or(y, label_img[j])\n",
    "        for j in range(pre_img.shape[0]):\n",
    "            y_hat = np.logical_or(y_hat, pre_img[j])\n",
    "        IOU = calculate_iou(y_hat, y)\n",
    "        if names_temp[0] in R_type:\n",
    "            IOU_R.append(IOU)\n",
    "        else:\n",
    "            IOU_plane.append(IOU)\n",
    "\n",
    "\n",
    "print('avg plane IOU', sum(IOU_plane)/len(IOU_plane))\n",
    "print('avg R IOU', sum(IOU_R)/len(IOU_R))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#generate images\n",
    "from segment_anything.utils.transforms import ResizeLongestSide\n",
    "resize_transform = ResizeLongestSide(sam.image_encoder.img_size)\n",
    "\n",
    "def prepare_image(image, transform, device):\n",
    "    image = transform.apply_image(image)\n",
    "    image = torch.as_tensor(image, device=device.device)\n",
    "    print('before permute', image.shape)\n",
    "    return image.permute(2, 0, 1).contiguous()\n",
    "\n",
    "\n",
    "for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "    data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "    labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "    bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "    print(data.shape, labels.shape, bboxes.shape)\n",
    "    boxes_np = bboxes.detach().cpu().numpy()\n",
    "    # labels, data = labels.to(device), data.to(device)\n",
    "    bboxes = bboxes.to(device)\n",
    "    data_np = data.permute(0, 2, 3, 1)\n",
    "    data_np = data_np.cpu().numpy()\n",
    "    data_np = data_np.astype(np.uint8)\n",
    "    print(data.shape)\n",
    "    \n",
    "    batched_input = []\n",
    "    for i in range(data.shape[0]):\n",
    "        img_tmp = prepare_image(data_np[i], resize_transform, sam)\n",
    "        print(img_tmp.shape)\n",
    "        box_tmp = resize_transform.apply_boxes_torch(bboxes[i], data[i].shape[:2])\n",
    "        print(box_tmp.shape)\n",
    "        input = {'image': prepare_image(data_np[i], resize_transform, sam),\n",
    "         'boxes': resize_transform.apply_boxes_torch(bboxes[i], data_np[i].shape[:2]),\n",
    "         'original_size': data_np[i].shape[:2]}\n",
    "        batched_input.append(input)\n",
    "    batched_output = sam(batched_input, multimask_output=False)\n",
    "    print('mask shape:', batched_output[0]['masks'].shape)\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        fig = plt.figure(figsize=(10, 10))\n",
    "        ax = fig.add_subplot(111)\n",
    "        img = data[i].cpu().numpy()\n",
    "        img = img.transpose(1, 2, 0)\n",
    "        # img = data_np[0].astype(float)\n",
    "        ax.imshow(img/255.)\n",
    "\n",
    "        # for mask in batched_output[i]['masks']:\n",
    "        #     show_mask(mask.cpu().numpy(), ax, random_color=False)\n",
    "        \n",
    "        # for box in boxes_np[i]:\n",
    "        #     show_box(box, ax)\n",
    "        ax.axis(\"off\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('defect/output/original/{}_{}.png'.format(names_temp[0], i))\n",
    "        # plt.shxianow()\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for step, (labels, data, bboxes, names_temp) in enumerate(test_dataloader):\n",
    "    data = torch.flatten(data, start_dim=0, end_dim=1)\n",
    "    labels = torch.flatten(labels, start_dim=0, end_dim=1)\n",
    "    bboxes = torch.flatten(bboxes, start_dim=0, end_dim=1)\n",
    "    print(data.shape, labels.shape, bboxes.shape)\n",
    "    data_np = data.permute(0, 2, 3, 1)\n",
    "    data_np = data_np.cpu().numpy()\n",
    "    data_np = data_np.astype(np.uint8)\n",
    "    print(data.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "medsam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
